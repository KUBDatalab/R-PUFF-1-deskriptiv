---
title: "Multipel lineær regression - og polynomisk"
teaching: 10
exercises: 5
questions:
- "Hvordan fitter jeg lineære modeller af mere end en parameter?"
- "Hvordan fitter jeg polynomiske modeller?"
objectives:
- "FIXME"
keypoints:
- "FIXME"
source: Rmd
math: yes
---

```{r, include = FALSE}
source("../bin/chunk-options.R")
knitr_fig_path("05-")
# source("../bin/download_data.R")
library(tidyverse)
```

# NB R-eksempler til modul 3 - ikke færdig!

Vi arbejder videre med fev datasættet. Først indlæser vi biblioteker:

```{r eval = F}
library(tidyverse)
```

Og så indlæser vi datasættet:
```{r eval = F}
fev <- read_csv("data/FEV.csv")
```
```{r echo=F}
fev <- read_csv("../data/FEV.csv")
```


Vi kommer i øvelser til at arbejde med BONEDEN datasættet. Det læser vi også ind:

```{r eval = F}
boneden <- read_csv("data/BONEDEN.csv")
```
```{r echo=F}
boneden <- read_csv("../data/BONEDEN.csv")
```



## Multipel lineær regression

Hvordan gør vi?

```{r}
model1 <- lm(FEV ~Age +Hgt, data = fev)
summary(model1)
```

Hvad hvis vi vil have en kategorisk variabel i modellen?

```{r}
model2 <- lm(FEV ~Age + Hgt + factor(Sex), data = fev)
summary(model2)
```

Hvis R skal kunne håndtere kategoriske variable korrekt, er vi nødt til at 
fortælle R at det er en kategorisk variabel. Det gør vi ved at pakke
variablen ind i `factor()`. 

Og hvis vi vil have to kategoriske variable i modellen?

```{r}
model3 <- lm(FEV ~ Age + Hgt + factor(Sex) + factor(Smoke), data = fev)
summary(model3)
```
### Husk også den deskreptive statistik!

Hvor mange observationer har vi blandt de kategoriske variable:
```{r}
table(smoke = fev$Smoke, sex = fev$Sex)
```



Nu skal I selv! Vi starter med model1:

> ## Forudsigelse fra model 1
> 
> Forudsig det bedste bud på FEV for en 10-årig, der er 150 cm
> høj.
>
> Husk - data er i tommer, så divider højden med 2.54.
>
> > ## Løsningsforslag
> > 
> > Model1 fortæller os hvad koefficienterne er:
> > ```{r}
> > summary(model1)
> > ```
> > 
> > Det giver denne model:
> >
> > FEV = -4.610466 + 0.054281*Age +  0.109712*Hgt
> > 
> > Højden beregner vi som 150/2.54 = 59.05512 i tommer.
> > 
> > Indsæt værdierne:
> > 
> > FEV = -4.610466 + 0.054281*10 +  0.109712*59.05512
> > 
> > eller: 2.411399
> >
> > Alternativ løsning:
> > 
> > ```{r eval = T}
> > nye_data <- data.frame(Age = 10, Hgt = 59.05512)
> > 
> > predict(model1, newdata = nye_data)
> > ```
> >
> > Denne fremgangsmåde er særligt nyttig når vi skal lave flere
> > forudsigelser.
> > 
> {: .solution}
{: .challenge}



> ## Hvilket interval "stoler" vi på?
>
> I hvilket interval er vi “95% sikre” på, at FEV vil være for en 10-årig 
> 150 cm høj person? 
> Hint: prædiktionsintervaller.
> 
> > ## Løsningsforslag
> > 
> > 
> > ```{r eval = T}
> > nye_data <- data.frame(Age = 10, Hgt = 59.05512)
> > predict(model1, newdata = nye_data, interval = "predict")
> > ```
> > 
> {: .solution}
{: .challenge}



> ## Giver det mening?
> 
> Hvad er vores bedste bud på FEV for en 0-årig, 150 cm høj person?
>
> Giver det mening?
> 
> > ## Løsningsforslag
> >
> > FEV = -4.610466 + 0.054281*0 +  0.109712*59.05512
> > 
> > eller: 1.868589
> > 
> > Nej. Vores model giver ikke nødvendigvis mening når vi bevæger os
> > udenfor det interval hvor vi har lavet vores model.
> >
> > Alternativ til beregning i hånden:
> > 
> > ```{r}
> > nye_data <- data.frame(Age = 0, Hgt = 150/2.54)
> > predict(model1, newdata = nye_data)
> > ```
> >
> {: .solution}
{: .challenge}

Og så fortsætter vi med model 2:

> ## Forudsigelse fra model 2 - piger
> 
> Hvad er modellens bedste bud på FEV for en 10-årig pige, der er 
> 150 cm høj?
>
> Husk, piger er kodet som "0", drenge som "1" i datasættet.
> 
>
> > ## Løsningsforslag
> > 
> > ```{r}
> > summary(model2)
> > ```
> > 
> > Her har vi koeeficienterne, og vi kan regne det ud i hånden:
> >
> > ```{r}
> > -4.448560 + 10 * 0.061364 + 150/2.54 * 0.104560 + 0 * 0.161112
> > ```
> > 
> > Eller, med predict funtionen:
> >
> > ```{r}
> > nye_data <- data.frame(Age = 10, Hgt = 150/2.54, Sex = factor(0))
> > predict(model2, newdata = nye_data)
> > ```
> > 
> {: .solution}
{: .challenge}


> ## Hvilket interval "stoler" vi på?
>
> I hvilket interval er vi “95% sikre” på, at FEV vil være for denne pige? 
> 
> Husk, piger er kodet som "0", drenge som "1" i datasættet.
> 
> > ## Løsningsforslag
> >
> > ```{r}
> > nye_data <- data.frame(Age = 10, Hgt = 150/2.54, Sex = factor(0))
> > predict(model2, newdata = nye_data, interval = "prediction")
> > ```
> >
> {: .solution}
{: .challenge}


> ## Forudsigelse fra model 2 - hvad med drengene?
> 
> Hvad er modellens bedste bud på FEV for en 10-årig dreng, der er 
> 150 cm høj?
>
> Sammenlign med forudsigelsen for en tilsvarende pige - giver forskellen 
> mening?
>
> Husk, piger er kodet som "0", drenge som "1" i datasættet.
> 
>
> > ## Løsningsforslag
> > 
> > ```{r}
> > summary(model2)
> > ```
> > 
> > Her har vi koeeficienterne, og vi kan regne det ud i hånden:
> >
> > ```{r}
> > -4.448560 + 10 * 0.061364 + 150/2.54 * 0.104560 + 1 * 0.161112
> > ```
> > 
> > Eller, med predict funtionen:
> >
> > ```{r}
> > nye_data <- data.frame(Age = 10, Hgt = 150/2.54, Sex = factor(1))
> > predict(model2, newdata = nye_data)
> > ```
> > 
> > Om forskellen giver mening? Både og. Modellen forudsiger at drenges
> > lungevolumen er 0.16 liter større end pigers. Så forudsigelsen skal
> > være højere. Det giver dog ikke nødvendigvis fysiologisk mening at 
> > der skulle være forskel på præpubertære børn. Måske indfyldelsen skyldes
> > at vi har betydeligt ældre børn i datasættet også?
> > 
> {: .solution}
{: .challenge}


Og til slut øvelser til model 3:


> ## Forudsigelser baseret på model 3
> 
> Forudsig bedste bud på FEV for en 10-årig pige med højde 150 cm, 
> som desuden ryger.
>
> > ## Løsningsforslag
> >
> > ```{r}
> > summary(model3)
> > ```
> > 
> > Her har vi koeeficienterne, og vi kan regne det ud i hånden:
> >
> > ```{r}
> > -4.456974 + 10 * 0.065509 + 150/2.54 * 0.104199 + 0 * 0.157103 + 1 * (-0.087246)
> > ```
> > 
> > Eller, med predict funtionen:
> >
> > ```{r}
> > nye_data <- data.frame(Age = 10, Hgt = 150/2.54, Sex = factor(0), Smoke = factor(1))
> > predict(model3, newdata = nye_data)
> > ```
> {: .solution}
{: .challenge}


> ## Hvilket interval "stoler" vi på?
> 
> I hvilket interval er vi “95% sikre” på, at FEV vil være for denne pige? 
>
> > ## Løsningsforslag
> > 
> > ```{r}
> > nye_data <- data.frame(Age = 10, Hgt = 150/2.54, Sex = factor(0), Smoke = factor(1))
> > predict(model3, newdata = nye_data, interval = "prediction")
> > ```
> >
> {: .solution}
{: .challenge}


> ## Og for en ikke-rygende pige
> 
> Forudsig bedste bud på FEV for en 10-årig pige med højde 150 cm, som ikke ryger.
> 
> Sammenlign med resultatet for en rygende pige. Hvad er forskellen? Siger
> modellen, at denne forskel bør være der?
>
> > ## Løsningsforslag
> > ```{r}
> > summary(model3)
> > ```
> > 
> > Her har vi koeeficienterne, og vi kan regne det ud i hånden:
> >
> > ```{r}
> > -4.456974 + 10 * 0.065509 + 150/2.54 * 0.104199 + 0 * 0.157103 + 0 * (-0.087246)
> > ```
> > 
> > Og med predict funktionen:
> > 
> > ```{r}
> > nye_data <- data.frame(Age = 10, Hgt = 150/2.54, Sex = factor(0), Smoke = factor(0))
> > predict(model3, newdata = nye_data)
> > ```
> >
> > 
> {: .solution}
{: .challenge}



## Vekselvirkning


Vi bygger to modeller, hvor FEV afhænger af alder og køn:

```{r}
modela <- lm(FEV ~ Age + factor(Sex), data = fev)
summary(modela)
```
```{r}
modelb <- lm(FEV ~ Age*factor(Sex), data = fev)
summary(modelb)
```
Skal vi plotte dem - er vi nødt til at beregne de forudsagte værdier for
forskellige aldre og køn.

Vi starter med at finde mulige værdier for alder og køn

```{r}
cAge <- unique(fev$Age)
sexes <- levels(factor(fev$Sex))

```

Så laver vi alle kombinationer af de to:

```{r}
pred_data <- crossing(Age = cAge, Sex = sexes)
head(pred_data)
```

Så tilføjer vi to kolonner, med forudsigelserne baseret på vores to modeller:

```{r}
pred_data <- pred_data %>% 
  mutate(modela = predict(modela, newdata = .)) %>% 
  mutate(modelb = predict(modelb, newdata = .))

```

Hvordan ser forudsigelserne ud for modela?

Vi plotter alle data som et scatterplot. 

Og så tilføjer vi to rette linier, baseret på vores forudsigelser. Hvis 
vi farvelægger efter "Sex", får vi to linier:

```{r}
fev %>% 
  ggplot(aes(Age, FEV, color = factor(Sex))) +
  geom_point() +
  geom_line(data = pred_data, aes(Age, modela, color = Sex)) +
  scale_color_manual(values = c("red", "blue"),
                     labels = c("Piger", "Drenge"),
                     name = "Køn") +
  ggtitle("Model a")
```
Og modelb - hvor vi har en vekselvirkning med:

```{r}
fev %>% 
  ggplot(aes(Age, FEV, color = factor(Sex))) +
  geom_point() +
  geom_line(data = pred_data, aes(Age, modelb, color = Sex)) +
  scale_color_manual(values = c("red", "blue"),
                     labels = c("Piger", "Drenge"),
                     name = "Køn") +
  ggtitle("Model b")
```

## Test af modeller

```{r}
library(car)
car::Anova(model1, model2)

```


```{r}
anova(model1, model2)
```

## Holder forudsætningerne?

qqplots af residualerne er en oplagt test. Funktionen `plot` af modellen giver
os netop det - men også tre andre plots, der er noget mere komplicerede at tolke.

Så lad os lave bare qqplottet.

Vi starter med at trække residualerne ud:

```{r}
residualer <- resid(modelb)
```

```{r}
qqnorm(residualer)
qqline(residualer, col = "red")
```
Eller, hvis vi gerne vil lave det i ggplot:
```{r}
data.frame(residualer) %>% 
  ggplot(aes(sample = residualer)) +
  geom_qq_line() +
  geom_qq()
```


## Polynomiske modeller


Vi kommer til at lave en polynomisk model af FEV mod Hgt:

```{r}
plot(fev$Hgt, fev$FEV)
```
Det kunne godt se ud som om FEV stiger lidt mere end bare lineært med højden.

Lineært fungerer OK:

```{r}
linear_model <- lm(FEV ~ Hgt, data = fev)
summary(linear_model)
```

Vi laver en polynomisk model:

```{r}
kubisk_model <- lm(FEV ~ Hgt + I(Hgt^2) + I(Hgt^3), data = fev)
summary(kubisk_model)
```
Det var _ikke_ imponerende...


> ## I() funktionen
> 
> Hvis ikke vi pakker x^2 ind i en I() funktion, vil R forsøge at fortolke hvad
> x^2 betyder. R vil prøve at fortolke ^2 som et interaktionsled. Og det kan 
> føre til underlige resultater.
> 
> I() funktionen undertrykker Rs fortolkning af ting, og sender x^2 videre til
> lm() funktionen, "as is", som det er, uden at R prøver at gøre ting ved det.
> 
{: .callout}

Går det bedre med et andengradspolynomium?

```{r}
kvadratisk_model <- lm(FEV ~ Hgt + I(Hgt^2), data = fev)
summary(kvadratisk_model)
```

_Meget_ bedre!

En forudsætning for modellen er at residualerne er normalfordelte.
Det kan vi teste ved at lave et QQ-plot:

```{r}
plot(kvadratisk_model) 
```


### Lad os sammenligne modellerne

Vi laver et scatter plot af vores data, og de tre modeller:

```{r}
fev %>% ggplot(aes(x = Hgt, y = FEV)) +
  geom_point() +
  geom_smooth(method = "lm", colour = "green", se = FALSE) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), colour = "blue", se = FALSE) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 3), colour = "red", se = FALSE)
```

Vi kan her gøre det enkelt, har vi mere komplekse modeller, er vi nødt til at 
lave forudsigelser for forskelligt input, og plotte resultaterne.

Prøv nu selv med boneden datasættet.





{% include links.md %}
