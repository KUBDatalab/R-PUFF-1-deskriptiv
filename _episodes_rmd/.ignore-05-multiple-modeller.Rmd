---
title: "Multipel lineær regression - og polynomisk"
teaching: 10
exercises: 5
questions:
- "Hvordan fitter jeg lineære modeller af mere end en parameter?"
- "Hvordan fitter jeg polynomiske modeller?"
objectives:
- "FIXME"
keypoints:
- "FIXME"
source: Rmd
math: yes
---

```{r, include = FALSE}
source("../bin/chunk-options.R")
knitr_fig_path("05-")
# source("../bin/download_data.R")
library(tidyverse)
```

# NB R-eksempler til modul 3 - ikke færdig!

## Multipel lineær regression
Vi har ikke taget stilling til hvilket datasæt der skal bruges som eksempel. 
Men kommer nok til at køre ca. samme model som øvelserne i forrige modul:

1. sådan gør du
2. gør det selv med et andet datasæt

Eksempelkode baserer sig aktuelt på mtcars datasættet.

Den multiple lineære regression opbygges på samme måde som den simple 
lineære regression. Formelnotationen er den samme. Nu er der blot flere
forklarende variable, der hver i sær tilføjes med et `+`:

```{r}
model <- lm(mpg ~ cyl + hp + wt, data = mtcars)
```

Det direkte output af modellen er en smule mere kompliceret end vi har set før -
der er flere variable, og derfor flere koefficienter:

```{r}
model
```
Dette kan vi tolke som, at `mpg`, miles pr gallon kan beskrives som:

$$ mpg = 38.75179 - 0.94162 * cyl - 0.01804 * hp - 3.16697 * wt$$ 
Jo flere hestekræfter, jo dårligere brændstoføkonomi. Jo tungere bil, jo dårligere
brændstoføkonomi. Men også dårligere brændstoføkonomi når bilen har flere cylindre.

Antallet af cylindre er teknisk set en kategorisk værdi. Bilmotorer kan have 
4, 6 eller 8 cylindre. Der er langt mellem de forbrændingsmotorer der har 5 cylindre.
Men der er ingen der har 4,3 cylindre. Der er også en sammenhæng mellem motorens
størrelse og antallet af cylindre. Og derfor "blander" vi de to parametre, cyl og hp.

Det er dårlig praksis...

Det mere detaljerede output af modellen får vi med `summary()` funktionen:

```{r}
summary(model)
```
Det er også lidt længere end vi ellers har set - for der er flere 
parametre at estimere.

```{r}
confint(model)
```
Er det en god model? Standard plotte funktionen giver os fire plots, der kan
bruges til at vurdere hvor god den er.
```{r}
plot(model)
```
Vi får fire plots, der alle handler om residualerne. En vigtig forudsætning for
den lineære regression er netop at residualerne er normalfordelte og tilfældige.

*Residuals vs Fitted* giver os residualerne af de fittede værdier. Altså, hvis 
cyl, hp og wt er hvad de nu er, hvor meget skulle mpg så være? Og hvad er mpg i
virkeligheden? De bør ligge helt tilfældigt. Hvis det ser ud som om der er 
mønstre, er der et eller andet vores model ikke har fanget.

*Q-Q residuals* er en visuel test af om resdiualerne er normalfordelte. Punkterne
bør ligge langs den lige linie. Det gør de sjældent helt.

*Scale-Location* viser os om spredningen af residualerne ændrer sig systematisk
med de fittede værdier. De skal helst ligge tilfældigt omkring en ret, horisontal
linie med værdien 0.

*Residuals vs Leverage* hjælper os til at identificere datapunkter, der har 
uforholdsmæssig indflydelse, "leverage" på modellen. Man kan forstå det som "hvis
dette punkt blev pillet ud af datasættet, ville parametrene i modellen så ændre sig
markant". Cook's distance som man kan se i plottet, giver os et bud på om 
et punkt ændrer parametrene markant.



## Polynomial regression

Den regression vi forsøger at lave er:

$$ y = a*x + b*x^2 + c$$

Det er i en vis forstand nøjagtig det samme, som hvis vi i vores datasæt 
beregnede en ny variabel, z, der var lig med $x^2$. I stedet for at gøre det,
lægger vi det ind i formelnotationen vi giver `lm()` funktionen direkte:

```{r}
a <- 1:10
b <- 1 + 2 * a + 3 * a^2 + rnorm(10)  # Simulerer responsvariable med støj
data <- tibble(x = a, y = b)
model <- lm(y ~ x + I(x^2), data = data)
summary(model)
```


> ## I() funktionen
> 
> Hvis ikke vi pakker x^2 ind i en I() funktion, vil R forsøge at fortolke hvad
> x^2 betyder. R vil prøve at fortolke ^2 som et interaktionsled. Og det kan 
> føre til underlige resultater.
> 
> I() funktionen undertrykker Rs fortolkning af ting, og sender x^2 videre til
> lm() funktionen, "as is", som det er, uden at R prøver at gøre ting ved det.
> 
{: .callout}



```{r}
confint(model)
```

{% include links.md %}
