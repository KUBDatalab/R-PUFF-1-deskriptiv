---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 06-logistisk-regression.md in _episodes_rmd/
title: "Kategoriske data og logistiske regressioner"
teaching: 10
exercises: 5
questions:
- "FIXME"
objectives:
- "FIXME"
keypoints:
- "FIXME"
source: Rmd
math: yes
---



# R-eksempler til modul 4

Vi fortsætter med FEV datasættet, men skal også bruge nogen andre


~~~
library(tidyverse)
fev <- read_csv("data/FEV.csv")
~~~
{: .language-r}

~~~
Rows: 654 Columns: 6
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (6): Id, Age, FEV, Hgt, Sex, Smoke

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
~~~
{: .output}
### Indlæs estradl datasættet:

Vi kommer også til at arbejde med dette datasæt. Download og indlæs:


~~~
download.file("https://raw.githubusercontent.com/KUBDatalab/R-PUFF/main/data/ESTRADL.csv", 
              "data/ESTRADL.csv", 
              mode = "wb")
estradl <- read_csv("data/ESTRADL.csv")
~~~
{: .language-r}

~~~
Rows: 211 Columns: 10
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (10): Id, Estradl, Ethnic, Entage, Numchild, Agefbo, Anykids, Agemenar, ...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
~~~
{: .output}


## Antalstabeller

Vi har set hvordan man laver antalstabeller:


~~~
tabel <- table(Sex = fev$Sex, smoke = fev$Smoke)
tabel
~~~
{: .language-r}



~~~
   smoke
Sex   0   1
  0 279  39
  1 310  26
~~~
{: .output}

Vi vil gerne have totaler tilføjet. Det kan vi gøre med funktionen `addmargins()`:


~~~
addmargins(tabel)
~~~
{: .language-r}



~~~
     smoke
Sex     0   1 Sum
  0   279  39 318
  1   310  26 336
  Sum 589  65 654
~~~
{: .output}

## Hvordan med sandsynlighederne?

Vi kan regne det i hånden, det så vi på sliden:

$$ \pi_i = P(X_i = 1)$$ 
$$\pi_{female} = \frac{279}{318} = 0.8774 $$ 

og

$$\pi_{male} = \frac{310}{336} = 0.9226 $$ 

### Og hvis vi er dovne

Vi kan også bruge en funktion, `prop.table()` giver os tallene direkte, men vi 
skal huske at fortælle om vi bruger summen fra kolonner, eller rækker. Her er det
summen i rækkerne. Det angiver vi med `margin = 1`  i funktionen:


~~~
prop.table(tabel, margin = 1)
~~~
{: .language-r}



~~~
   smoke
Sex          0          1
  0 0.87735849 0.12264151
  1 0.92261905 0.07738095
~~~
{: .output}

## Spredning på estimaterne:

Først for pigerne:


~~~
p_female <- 0.8774 
sd_female <- sqrt(p_female*(1-p_female)/318)
sd_female
~~~
{: .language-r}



~~~
[1] 0.01839206
~~~
{: .output}
Og så for drengene:


~~~
p_male <- 0.9226
sd_male <- sqrt(p_male*(1-p_male)/318)
sd_male
~~~
{: .language-r}



~~~
[1] 0.01498524
~~~
{: .output}

## Konfidensintervallerne:


~~~
p_female + c(-1,1)*1.96*sd_female
~~~
{: .language-r}



~~~
[1] 0.8413516 0.9134484
~~~
{: .output}

~~~
p_male + c(-1,1)*1.96*sd_male
~~~
{: .language-r}



~~~
[1] 0.8932289 0.9519711
~~~
{: .output}


Vi kan også beregne det eksakt:


~~~
binom.test(tabel[2,1], sum(tabel[2,]))
~~~
{: .language-r}



~~~

	Exact binomial test

data:  tabel[2, 1] and sum(tabel[2, ])
number of successes = 310, number of trials = 336, p-value < 2.2e-16
alternative hypothesis: true probability of success is not equal to 0.5
95 percent confidence interval:
 0.8886735 0.9488316
sample estimates:
probability of success 
              0.922619 
~~~
{: .output}
## Risikodifferensen

Ret enkelt når først vi har sandsynlighederne:


~~~
p_male - p_female
~~~
{: .language-r}



~~~
[1] 0.0452
~~~
{: .output}
Og standardafvigelsen på det tal finder vi ved


~~~
sqrt(sd_male^2 + sd_female^2)
~~~
{: .language-r}



~~~
[1] 0.02372394
~~~
{: .output}

Prøv selv!



> ## Øvelse på estradl datasættet
> 
> Nøjagtig samme øvelse, nu er vi blot i et andet datasæt, så vi ser på
> variablene "Anykids" og "Ethnic"
> 
> Anykids har manglende data. Det er kodet med et 9-tal. Start med at fjerne 
> dem fra datasættet. Husk også at konvertere de to variable til faktorer!
> 
> Hvad er sandsynligheden for at have børn for afro-amerikanere (ethnic = 0),
> kontra sandsynligheden for at have børn for caucasier
>
> > ## Løsningsforslag
> > 
> > Start med at sortere rækker hvor værdien i "Anykids" er lig 9. Og konverter til 
> > kategoriske variable:
> > 
> > 
> > ~~~
> > estradl_renset <- estradl %>% 
> >    filter(Anykids != 9) %>% 
> >    mutate(Anykids = factor(Anykids),
> >           Ethnic = factor(Ethnic))
> > ~~~
> > {: .language-r}
> >
> > Lav tabellen, og brug addmargins til at give summerne:
> > 
> > 
> > ~~~
> > estra_tabel <- table( ethnic = estradl_renset$Ethnic, anykids = estradl_renset$Anykids)
> > addmargins(estra_tabel)
> > ~~~
> > {: .language-r}
> > 
> > 
> > 
> > ~~~
> >       anykids
> > ethnic   0   1 Sum
> >    0    52   7  59
> >    1    96  51 147
> >    Sum 148  58 206
> > ~~~
> > {: .output}
> >
> > Herefter kan vi beregne det direkte:
> > 
> > ~~~
> > p_aa <- 7/59
> > p_aa
> > ~~~
> > {: .language-r}
> > 
> > 
> > 
> > ~~~
> > [1] 0.1186441
> > ~~~
> > {: .output}
> >
> > 
> > ~~~
> > p_ca <- 51/147
> > p_ca
> > ~~~
> > {: .language-r}
> > 
> > 
> > 
> > ~~~
> > [1] 0.3469388
> > ~~~
> > {: .output}
> >
> {: .solution}
{: .challenge}

> ## Hvad med spredningerne?
> 
> Beregn spredningen på de to estimater
> 
> > ## Løsningsforslag
> >
> > Tallene vi skal brug får vi fra tabellen:
> > 
> > ~~~
> > addmargins(estra_tabel)
> > ~~~
> > {: .language-r}
> > 
> > 
> > 
> > ~~~
> >       anykids
> > ethnic   0   1 Sum
> >    0    52   7  59
> >    1    96  51 147
> >    Sum 148  58 206
> > ~~~
> > {: .output}
> >
> > Og så kan vi beregne for afro-amerikanere
> > 
> > ~~~
> > sd_aa <- sqrt(p_aa*(1-p_aa)/59)
> > sd_aa
> > ~~~
> > {: .language-r}
> > 
> > 
> > 
> > ~~~
> > [1] 0.04209909
> > ~~~
> > {: .output}
> >
> > Og for kaukaiser:
> >
> > 
> > ~~~
> > sd_ca <- sqrt(p_ca*(1-p_ca)/147)
> > sd_ca
> > ~~~
> > {: .language-r}
> > 
> > 
> > 
> > ~~~
> > [1] 0.03925949
> > ~~~
> > {: .output}
> >
> {: .solution}
{: .challenge}

> ## Konfidensintervallerne
>
> Beregn til sidst konfidensintervallerne for de to estimater, baseret
> på estimaterne og standardafvigelserne.
>
> > ## Løsningsforslag
> >
> > For afro-amerikanere:
> > 
> > ~~~
> > p_aa + c(-1,1)*1.96*sd_aa
> > ~~~
> > {: .language-r}
> > 
> > 
> > 
> > ~~~
> > [1] 0.03612986 0.20115828
> > ~~~
> > {: .output}
> >
> > Og for kaukaser:
> > 
> > ~~~
> > p_ca + c(-1,1)*1.96*sd_ca
> > ~~~
> > {: .language-r}
> > 
> > 
> > 
> > ~~~
> > [1] 0.2699902 0.4238874
> > ~~~
> > {: .output}
> >
> {: .solution}
{: .challenge}


## Relativ risiko

Den relative risiko finder vi ved at dividere den ene sandsynlighed med den anden:


~~~
RR <- p_female/p_male
RR
~~~
{: .language-r}



~~~
[1] 0.951008
~~~
{: .output}
### Standardafvigelsen

Den logaritmerede vel at mærke!


~~~
sd_log_RR <- sqrt(1/279-1/318+1/310-1/336) 
sd_log_RR
~~~
{: .language-r}



~~~
[1] 0.02625245
~~~
{: .output}
### Konfidensintervallet

Og med både estimatet på den relative risiko, og dens standardafvigelse, kan vi 
beregne konfidensintervallet:


~~~
KI <- log(RR) + c(-1,1)*1.96*sd_log_RR
KI
~~~
{: .language-r}



~~~
[1] -0.101687590  0.001222025
~~~
{: .output}

Husk! Det var det logaritmerede konfidensinterval. Hvis vi vil have det
"rigtige" skal vi exponentiere:


~~~
exp(KI)
~~~
{: .language-r}



~~~
[1] 0.9033117 1.0012228
~~~
{: .output}



## Odds ratio

### Odds ratio og konfidensintervaller for fev-datasættet

Nicolais slides var mere nice end vi har set det her datasæt før. I stedet
for 0 og 1, er det oversat til "female" og "male". Lad os lige gøre det 
også så vi selv få lækre tabeller

Vi starter med at omkode fev, så vi ikke skal huske at Sex = 0 betyder 
kvinder, og at Smoke = 0 betyder ikke-ryger.

Dernæst mutater vi de to variable til at være faktorer, altså kategoriske
variable. Endelig sætter vi "smoker" til at være den første værdi i den 
kategoriske variabel Smoke. Og så gemmer vi det hele i en ny dataframe
som vi kalder fev_clean:



~~~
fev_clean <- fev %>% 
  mutate(Sex = case_when(
    Sex == 0 ~ "female",
    Sex == 1 ~ "male"
  )) %>% 
  mutate(Smoke = case_when(
    Smoke == 0 ~ "non-smoker",
    Smoke == 1 ~ "smoker"
  )) %>% 
  mutate(Sex = as.factor(Sex),
         Smoke = as.factor(Smoke)) %>% 
  mutate(Smoke = relevel(Smoke, ref = "smoker"))
~~~
{: .language-r}

Det data skal vi bruge senere. For nu, laver vi endnu et datasæt, hvor vi
kun ser på de to variable, Sex og Smoke:


~~~
fev_to_table <- fev_clean %>% 
  select(Sex, Smoke)
~~~
{: .language-r}


Så laver vi vores tabel med tælletallene:


~~~
cont_table_fev <- table(fev_to_table)
cont_table_fev
~~~
{: .language-r}



~~~
        Smoke
Sex      smoker non-smoker
  female     39        279
  male       26        310
~~~
{: .output}

Det ser mere lækkert ud!

### Chi-i-anden testen 

Først de forventede værdier:


~~~
chisq.test(cont_table_fev)$expected
~~~
{: .language-r}



~~~
        Smoke
Sex       smoker non-smoker
  female 31.6055   286.3945
  male   33.3945   302.6055
~~~
{: .output}
Og så selve testen:


~~~
chisq.test(cont_table_fev, correct = F)
~~~
{: .language-r}



~~~

	Pearson's Chi-squared test

data:  cont_table_fev
X-squared = 3.739, df = 1, p-value = 0.05316
~~~
{: .output}

Og til sidst fisher testen:


~~~
fisher.test(cont_table_fev)
~~~
{: .language-r}



~~~

	Fisher's Exact Test for Count Data

data:  cont_table_fev
p-value = 0.06661
alternative hypothesis: true odds ratio is not equal to 1
95 percent confidence interval:
 0.9603893 2.9289485
sample estimates:
odds ratio 
   1.66535 
~~~
{: .output}
> ## Hvorfor logaritmerer vi?
> 
> Som der står i sliden, odds går mellem 0 og uendelig. Det er noget bøvl
> Eksempelvis er odds 1:4 det samme forhold som 4:1. Men regner vi det ud
> sammenligner vi 0.25 med 4. 
> 
> Tager vi logaritmen - så er tallene pludselig pæne og symmetriske:
> 
> ~~~
> Error in eval(expr, envir, enclos): object 'odds' not found
> ~~~
> {: .error}
>
{: .callout}


## Logistisk regression

### En hjælpefunktion

Allerførst - sliden nævner en `ilogit()` funktion - og det er praktisk at kunne
gå fra log-odds til p uden selv at regne så meget. Så vi skriver en funktion.

Det er ikke specielt kompliceret.

Hvis vi har en sandsynlighed p, kan vi regne log-odds, her kalder vi den x, 
ved denne formel:

$$x = \log(\frac{p}{1-p})$$

Når vi skriver udtrykket om for at isolere p, får vi:

$$p = \frac{e^x}{1+ e^x} $$

Kender vi x, kan vi regne det ud:


~~~
exp(x)/(1+exp(x))
~~~
{: .language-r}

Det pakker vi ind i en særlig funktion, og giver den et navn:


~~~
ilogit <- function(x){
  exp(x)/(1+exp(x))
}
~~~
{: .language-r}

Og så har vi en funktion vi kan bruge til at regne en sandsynlighed ud, når vi 
har en log-odds ratio:


~~~
ilogit(0.9)
~~~
{: .language-r}



~~~
[1] 0.7109495
~~~
{: .output}
Fikst!

## En generel lineær model

Vi bruger glm, som kan håndtere andet end simple lineære modeller


~~~
glmfev <- glm(Smoke ~Sex, family = "binomial", data = fev_clean)
glmfev
~~~
{: .language-r}



~~~

Call:  glm(formula = Smoke ~ Sex, family = "binomial", data = fev_clean)

Coefficients:
(Intercept)      Sexmale  
     1.9677       0.5108  

Degrees of Freedom: 653 Total (i.e. Null);  652 Residual
Null Deviance:	    423.4 
Residual Deviance: 419.7 	AIC: 423.7
~~~
{: .output}

Når vi ser nærmere på den, bruger vi summary():

~~~
summary(glmfev)
~~~
{: .language-r}



~~~

Call:
glm(formula = Smoke ~ Sex, family = "binomial", data = fev_clean)

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   1.9677     0.1710  11.510   <2e-16 ***
Sexmale       0.5108     0.2663   1.918   0.0551 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 423.45  on 653  degrees of freedom
Residual deviance: 419.69  on 652  degrees of freedom
AIC: 423.69

Number of Fisher Scoring iterations: 5
~~~
{: .output}

### Konfidensintervaller på estimaterne

Her kan vi bruge `confint()` funktionen. Vi skal huske at det er log-odds, så 
vi skal exponentiere:


~~~
exp(confint(glmfev))
~~~
{: .language-r}



~~~
Waiting for profiling to be done...
~~~
{: .output}



~~~
                2.5 %    97.5 %
(Intercept) 5.1852530 10.153411
Sexmale     0.9941708  2.836364
~~~
{: .output}

Hvis vi kun er interesserede i "hældningen" kan vi nøjes med at trække den ud:


~~~
exp(confint(glmfev))[2,]
~~~
{: .language-r}



~~~
Waiting for profiling to be done...
~~~
{: .output}



~~~
    2.5 %    97.5 % 
0.9941708 2.8363636 
~~~
{: .output}

Her bruger vi en notation med kantede paranteser. Vi beder om række 2 (foran
kommaet), og alle kolonner (det får vi ved at lade være med at skrive noget 
efter kommaet)

## Konfidensinterval?

Vi starter med at se på koefficienterne fra summary funktionen:


~~~
summary(glmfev)$coef
~~~
{: .language-r}



~~~
             Estimate Std. Error   z value     Pr(>|z|)
(Intercept) 1.9676501  0.1709540 11.509825 1.177169e-30
Sexmale     0.5108256  0.2662941  1.918276 5.507602e-02
~~~
{: .output}

Vi skal bruge Estimate og Std.Error kolonnerne.

Den første får vi med

~~~
summary(glmfev)$coef[2,1]
~~~
{: .language-r}



~~~
[1] 0.5108256
~~~
{: .output}

Den anden med 

~~~
summary(glmfev)$coef[2,2]
~~~
{: .language-r}



~~~
[1] 0.2662941
~~~
{: .output}

Og så kan vi hægte det hele sammen. I stedet for estimatet 1.96, bruger
vi qnorm(0.975), der giver os det eksakte tal. Vi skal også huske at 
exponentiere:


~~~
exp(summary(glmfev)$coef[2,1] + c(-1,1)*qnorm(0.975)*summary(glmfev)$coef[2,2])
~~~
{: .language-r}



~~~
[1] 0.9889601 2.8087864
~~~
{: .output}

### Sandsynligheden for ikke at ryge som kvinde

Sandsynligheden for _ikke_ at ryge som kvinde kan vi trække ud af modellen. Den
giver os odds-ratio logaritmeret, så vi bruger vores hjælpefunktion fra før, for 
at få sandsynligheden:


~~~
ilogit(summary(glmfev)$coef[1,1])
~~~
{: .language-r}



~~~
[1] 0.8773585
~~~
{: .output}

Vi kunne også få det fra tabellen:



~~~
cont_table_fev
~~~
{: .language-r}



~~~
        Smoke
Sex      smoker non-smoker
  female     39        279
  male       26        310
~~~
{: .output}
Og får resultatet:

~~~
279/318
~~~
{: .language-r}



~~~
[1] 0.8773585
~~~
{: .output}

Det samme resultat!

### Hvordan med odds-ratio?

Vi trækker koefficienten ud, og exponentierer den:


~~~
exp(summary(glmfev)$coef[2,1])
~~~
{: .language-r}



~~~
[1] 1.666667
~~~
{: .output}

Det kunne vi også gøre med tabellen:


~~~
(310*39)/(26*279)
~~~
{: .language-r}



~~~
[1] 1.666667
~~~
{: .output}


## Rygestatus forudsagt fra alder:

Modellen bygger vi som ellers, nu forudsiger vi "bare" noget kategorisk.



~~~
glmfevcont <- glm(Smoke ~ Age, family=binomial, data = fev_clean)
summary(glmfevcont)
~~~
{: .language-r}



~~~

Call:
glm(formula = Smoke ~ Age, family = binomial, data = fev_clean)

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  7.74391    0.70890  10.924   <2e-16 ***
Age         -0.48364    0.05513  -8.773   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 423.45  on 653  degrees of freedom
Residual deviance: 318.56  on 652  degrees of freedom
AIC: 322.56

Number of Fisher Scoring iterations: 6
~~~
{: .output}

### Sandsynligheden for ikke at ryge ved intercept

Vi trækker interceptet ud af summary. Det er en log-odds-ratio. Så kører vi 
vores hjælpefunktion på det tal for at få sandsynligheden:



~~~
ilogit(summary(glmfevcont)$coef[1,1])
~~~
{: .language-r}



~~~
[1] 0.9995668
~~~
{: .output}

### Og hvad stiger sandsynligheden med pr år?

Samme metodik - men pas på med fortolkingen.


~~~
exp(summary(glmfevcont)$coef[2,1])
~~~
{: .language-r}



~~~
[1] 0.6165355
~~~
{: .output}


## Og med flere prediktorer!


~~~
glmfevmult <- glm(Smoke ~ Sex + Age, family = "binomial", data = fev_clean) 
summary(glmfevmult)
~~~
{: .language-r}



~~~

Call:
glm(formula = Smoke ~ Sex + Age, family = "binomial", data = fev_clean)

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  7.58607    0.72054  10.528   <2e-16 ***
Sexmale      0.79294    0.30819   2.573   0.0101 *  
Age         -0.50087    0.05707  -8.776   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 423.45  on 653  degrees of freedom
Residual deviance: 311.68  on 651  degrees of freedom
AIC: 317.68

Number of Fisher Scoring iterations: 6
~~~
{: .output}

### Forudsigelser

Nu har vi en model, og den kan vi bruge til at lave forudsigelser, 
ganske som tidligere, her med en 18-årig mand:


~~~
predict(glmfevmult, data.frame(Sex = "male", Age = 18), type = "respons")
~~~
{: .language-r}



~~~
        1 
0.3460051 
~~~
{: .output}

Og en 18-årig kvinde:


~~~
predict(glmfevmult, data.frame(Sex = "female", Age = 18), type = "respons")
~~~
{: .language-r}



~~~
        1 
0.1931638 
~~~
{: .output}

Og en 10-årig pige:


~~~
predict(glmfevmult, data.frame(Sex = "female", Age = 10), type = "respons")
~~~
{: .language-r}



~~~
        1 
0.9293912 
~~~
{: .output}


## Og en øvelse - ESTRADL

Vi prøver at lave en multipel logistisk regression på ESTRADL datasættet.

Byg en model der forudsiger sandsynligheden for at have børn, baseret på 
etnicitet og alder (Entage)

glm(Anykids ~ Ethnic + Entage, family = "binomial", data = estradl)
{% include links.md %}
